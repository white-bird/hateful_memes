{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "import sklearn\n",
    "import time\n",
    "import datetime,math,os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import lightgbm as lgb\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import traceback\n",
    "from torchvision import transforms as T\n",
    "\n",
    "MODE = 'TEST' # DEV/TEST\n",
    "ISPREDICT = True  \n",
    "weight_path = '../model/weights'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8500, 8), (640, 8), (1000, 8))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练集生成\n",
    "train = pd.read_csv('../input2/train.csv')\n",
    "train2 = pd.read_csv('../input2/dev1.csv')\n",
    "train3 = pd.read_csv('../input2/dev2.csv')\n",
    "train2 = train3.append(train2).drop_duplicates('id',keep='first')\n",
    "test = pd.read_csv('../input2/test1.csv')\n",
    "test2 = pd.read_csv('../input2/test2.csv')\n",
    "train.shape,train2.shape,test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findId(id):\n",
    "    if id in train.id.tolist():\n",
    "        return \"train\"\n",
    "    if id in train2.id.tolist():\n",
    "        return \"train2\"\n",
    "    if id in train3.id.tolist():\n",
    "        return \"train3\"\n",
    "    if id in test.id.tolist():\n",
    "        return \"test\"\n",
    "    if id in test2.id.tolist():\n",
    "        return \"test2\"\n",
    "    return 'unk'\n",
    "\n",
    "same_id_dict = {}\n",
    "for line in open('./same_id.csv','r'):\n",
    "    if line == '':\n",
    "        continue\n",
    "    array = line.strip().split(' ')\n",
    "    same_id_dict[int(array[1])] = int(array[0])\n",
    "\n",
    "for id,v in same_id_dict.items():\n",
    "    temp_id = id\n",
    "    while(True):\n",
    "        if same_id_dict.get(temp_id, -1) != -1:\n",
    "            temp_id = same_id_dict[temp_id]\n",
    "            \n",
    "        else:\n",
    "            break\n",
    "    same_id_dict[id] = temp_id\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_dev = pd.read_csv('../mmf/coco_output2.csv')\n",
    "id_mmf = {}\n",
    "cache = coco_dev[['id','proba']].values\n",
    "for i in range(cache.shape[0]):\n",
    "    id_mmf[cache[i,0]] = cache[i,1]\n",
    "    \n",
    "coco_dev = pd.read_csv('../mmf/coco_output.csv')\n",
    "cache = coco_dev[['id','proba']].values\n",
    "for i in range(cache.shape[0]):\n",
    "    id_mmf[cache[i,0]] = cache[i,1]\n",
    "\n",
    "coco_dev = pd.read_csv('../mmf/coco_sub.csv')\n",
    "cache = coco_dev[['id','proba']].values\n",
    "for i in range(cache.shape[0]):\n",
    "    id_mmf[cache[i,0]] = cache[i,1]\n",
    "    \n",
    "coco_dev = pd.read_csv('../mmf/coco_sub2.csv')\n",
    "cache = coco_dev[['id','proba']].values\n",
    "for i in range(cache.shape[0]):\n",
    "    id_mmf[cache[i,0]] = cache[i,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_feat = {}\n",
    "id_weight_nltk = {}\n",
    "cache = train[['id','label','nltk1','nltk2','nltk3','nltk4']].values\n",
    "for i in range(cache.shape[0]):\n",
    "    id_feat[cache[i,0]]  = cache[i,2:]\n",
    "    if cache[i,1] == 1:\n",
    "        id_weight_nltk[cache[i,0]] = 1 - np.clip(cache[i,4] - cache[i,2],0,0.5)\n",
    "    else:\n",
    "        id_weight_nltk[cache[i,0]] = 1 - np.clip(cache[i,2] - cache[i,4],0,0.5)\n",
    "\n",
    "cache = train2[['id','label','nltk1','nltk2','nltk3','nltk4']].values\n",
    "for i in range(cache.shape[0]):\n",
    "    id_feat[cache[i,0]]  = cache[i,2:]\n",
    "    if cache[i,1] == 1:\n",
    "        id_weight_nltk[cache[i,0]] = 1 - np.clip(cache[i,4] - cache[i,2],0,0.5)\n",
    "    else:\n",
    "        id_weight_nltk[cache[i,0]] = 1 - np.clip(cache[i,2] - cache[i,4],0,0.5)\n",
    "\n",
    "        \n",
    "cache = test[['id','label','nltk1','nltk2','nltk3','nltk4']].values\n",
    "for i in range(cache.shape[0]):\n",
    "    id_feat[cache[i,0]]  = cache[i,2:]\n",
    "    \n",
    "cache = test2[['id','label','nltk1','nltk2','nltk3','nltk4']].values\n",
    "for i in range(cache.shape[0]):\n",
    "    id_feat[cache[i,0]]  = cache[i,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm, tqdm_notebook\n",
    "img_size = 128\n",
    "def resize_to_square(im):\n",
    "    old_size = im.shape[:2] # old_size is in (height, width) format\n",
    "    ratio = float(img_size)/max(old_size)\n",
    "    new_size = tuple([int(x*ratio) for x in old_size])\n",
    "    # new_size should be in (width, height) format\n",
    "    im = cv2.resize(im, (new_size[1], new_size[0]))\n",
    "    delta_w = img_size - new_size[1]\n",
    "    delta_h = img_size - new_size[0]\n",
    "    top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
    "    left, right = delta_w//2, delta_w-(delta_w//2)\n",
    "    color = [0, 0, 0]\n",
    "    new_im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT,value=color)\n",
    "    return new_im\n",
    "\n",
    "def load_image(path, name):\n",
    "    image = (Image.open(path + name))\n",
    "    \n",
    "    transform1 = T.Compose([\n",
    "        T.Scale(img_size),\n",
    "        T.CenterCrop((img_size, img_size)),\n",
    "    ])\n",
    "    new_image = transform1(image)\n",
    "    new_image = np.array(new_image)\n",
    "    if len(new_image.shape) == 2:\n",
    "        new_image = np.repeat(new_image.reshape(img_size,img_size,1),3,axis = 2)\n",
    "    \n",
    "    if new_image.shape[2] > 3:\n",
    "        new_image = new_image[:,:,:3]\n",
    "    return new_image/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yingzhenzhe/.local/lib/python3.6/site-packages/torchvision/transforms/transforms.py:257: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
      "  \"please use transforms.Resize instead.\")\n"
     ]
    }
   ],
   "source": [
    "pic_cache = {}\n",
    "id_pic = {}\n",
    "id_text = {}\n",
    "id_label = {}\n",
    "cache = train[['id','img','label','text']].values\n",
    "for i in range(cache.shape[0]):\n",
    "    id_pic[cache[i,0]]  = cache[i,1]\n",
    "    id_label[cache[i,0]] = cache[i,2]\n",
    "    pic_cache[cache[i,0]] = load_image(\"../input2/data/\", cache[i,1])\n",
    "    id_text[cache[i,0]]  = cache[i,3]\n",
    "\n",
    "\n",
    "id_label2 = {}\n",
    "id_label3 = {}\n",
    "cache = train2[['id','img','label','text']].values\n",
    "for i in range(cache.shape[0]):\n",
    "    id_pic[cache[i,0]]  = cache[i,1]\n",
    "    if MODE == 'TEST':\n",
    "        id_label[cache[i,0]] = cache[i,2]\n",
    "    else:\n",
    "        id_label2[cache[i,0]] = cache[i,2]\n",
    "    pic_cache[cache[i,0]] = load_image(\"../input2/data/\", cache[i,1])\n",
    "    id_text[cache[i,0]]  = cache[i,3]\n",
    "\n",
    "ids_list = list(id_label.keys()) \n",
    "\n",
    "cache = test[['id','img','label','text']].values\n",
    "for i in range(cache.shape[0]):\n",
    "    id_pic[cache[i,0]]  = cache[i,1]\n",
    "    pic_cache[cache[i,0]] = load_image(\"../input2/data/\", cache[i,1])\n",
    "    id_text[cache[i,0]]  = cache[i,3]\n",
    "    \n",
    "cache = test2[['id','img','label','text']].values\n",
    "for i in range(cache.shape[0]):\n",
    "    id_pic[cache[i,0]]  = cache[i,1]\n",
    "    pic_cache[cache[i,0]] = load_image(\"../input2/data/\", cache[i,1])\n",
    "    id_text[cache[i,0]]  = cache[i,3]\n",
    "    if MODE == 'TEST':\n",
    "        id_label2[cache[i,0]] = random.choice([0,1])\n",
    "ids_list2 = list(id_label2.keys()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/04/2020 11:18:40 - INFO - transformers.file_utils -   PyTorch version 1.6.0 available.\n",
      "11/04/2020 11:18:41 - INFO - transformers.file_utils -   TensorFlow version 2.0.0 available.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import logging\n",
    "logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
    "                        datefmt = '%m/%d/%Y %H:%M:%S',\n",
    "                        level = logging.INFO)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import tokenizers\n",
    "from transformers import RobertaModel, RobertaConfig\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "tokenizer = tokenizers.ByteLevelBPETokenizer(\n",
    "            vocab_file='../input/roberta-base/vocab.json', \n",
    "            merges_file='../input/roberta-base/merges.txt', \n",
    "            lowercase=True,\n",
    "            add_prefix_space=True)\n",
    "\n",
    "max_seq_length = 96\n",
    "\n",
    "def get_input_data(text):\n",
    "    text = \" \" + \" \".join(text.lower().split())\n",
    "    encoding = tokenizer.encode(text)\n",
    "    ids = [0] + encoding.ids + [2]\n",
    "    offsets = [(0, 0)] * 4 + encoding.offsets + [(0, 0)]\n",
    "                \n",
    "    pad_len = max_seq_length - len(ids)\n",
    "    if pad_len > 0:\n",
    "        ids += [1] * pad_len\n",
    "        offsets += [(0, 0)] * pad_len\n",
    "    elif pad_len < 0:\n",
    "        ids = ids[:max_seq_length]\n",
    "        offsets = offsets[:max_seq_length]\n",
    "    ids = torch.tensor(ids)\n",
    "    masks = torch.where(ids != 1, torch.tensor(1), torch.tensor(0))\n",
    "        \n",
    "    return ids, masks\n",
    "\n",
    "class DensNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        preloaded = torchvision.models.resnet50(pretrained=True)\n",
    "        hidden1_size = 64\n",
    "        self.features = preloaded\n",
    "        self.features.conv1 = nn.Conv2d(3, 64, 7, 2, 3)\n",
    "        self.fci = nn.Linear(1000, hidden1_size, bias=True)\n",
    "        self.fct = nn.Linear(768 + 4, hidden1_size, bias=True)\n",
    "        self.fc2 = nn.Linear(hidden1_size * 3, 1, bias=True)\n",
    "#         del preloaded\n",
    "        \n",
    "        self.fc3 = nn.Linear(hidden1_size * 4, 32, bias=True)\n",
    "        self.fc4 = nn.Linear(32, 2, bias=True)\n",
    "        \n",
    "        config = RobertaConfig.from_pretrained(\n",
    "            '../input/roberta-base/config.json', output_hidden_states=True)    \n",
    "        self.roberta = RobertaModel.from_pretrained(\n",
    "            '../input/roberta-base/pytorch_model.bin', config=config)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fctext = nn.Linear(config.hidden_size, 16)\n",
    "        nn.init.normal_(self.fctext.weight, std=0.02)\n",
    "        nn.init.normal_(self.fctext.bias, 0)\n",
    "        \n",
    "        hidden_dim = 64\n",
    "        self.gate = nn.Linear(2 * hidden_dim, hidden_dim)\n",
    "        self.tabular_dense = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.text_dense = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.bn_gate = nn.BatchNorm1d(hidden_dim)\n",
    "        \n",
    "    def middle(self, x):\n",
    "        features = self.features(x[0])\n",
    "        out = F.relu(features, inplace=True)\n",
    "        out = self.dropout(out)\n",
    "        out = (self.fci(out))\n",
    "        \n",
    "        hs1, hs0, hs = self.roberta(x[1], x[2])\n",
    "        hs0 = torch.cat([hs0,x[3]],1)\n",
    "        hs0 = self.dropout(hs0)\n",
    "        hs0 = (self.fct(hs0))\n",
    "        return [out,hs0]       \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out,hs0 = self.middle(x)\n",
    "        out = (torch.cat([out - hs0,hs0 * out, hs0], 1))\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "    \n",
    "    def forward2(self, x):\n",
    "        out,hs0 = self.middle(x)\n",
    "        out1 = (torch.cat([out - hs0,hs0 * out, hs0], 1))\n",
    "        out1 = self.dropout(out1)\n",
    "        out1 = self.fc2(out1)\n",
    "        \n",
    "        out2 = (torch.cat([out * 0.0 - hs0,hs0 * out * 0.0, hs0], 1))\n",
    "        out2 = self.dropout(out2)\n",
    "        out2 = self.fc2(out2)\n",
    "\n",
    "        out3 = (torch.cat([out - hs0 * 0.0,hs0 * out * 0.0, hs0 * 0.0], 1))\n",
    "        out3 = self.dropout(out3)\n",
    "        out3 = self.fc2(out3)\n",
    "        return torch.cat([out1,out2,out3],1)\n",
    "\n",
    "    \n",
    "    def pair_forward(self, x1, x2):\n",
    "        result = []\n",
    "        for x in [x1,x2]:\n",
    "            out,hs0 = self.middle(x)\n",
    "            result.append(torch.cat([out,hs0],1))\n",
    "            \n",
    "        out = (self.fc3(torch.cat([result[0] - result[1],result[0] * result[1]], 1)))\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc4(out)\n",
    "        return out\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6937 6814 2000\n"
     ]
    }
   ],
   "source": [
    "img_pairs = []\n",
    "text_pairs = []\n",
    "for line in open('./img_pairs.csv','r'):\n",
    "    if line == '':\n",
    "        continue\n",
    "    array = line.strip().split(' ')\n",
    "    img_pairs.append([int(array[0]),int(array[1])])\n",
    "    \n",
    "for line in open('./text_pairs.csv','r'):\n",
    "    if line == '':\n",
    "        continue\n",
    "    array = line.strip().split(' ')\n",
    "    text_pairs.append([int(array[0]),int(array[1])])\n",
    "\n",
    "ids_list3 = [x for x in ids_list2]\n",
    "print(len(img_pairs),len(text_pairs),len(ids_list3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_pair = []\n",
    "id_sample_weight = {}\n",
    "for pairs in [text_pairs,img_pairs]:\n",
    "    id2cluster = {}\n",
    "    cluster2id = {}\n",
    "    clusterid = 0 \n",
    "    for line in pairs:\n",
    "        id0 = line[0]\n",
    "        id1 = line[1]\n",
    "        if id_label.get(id0,-1) == -1 and id_label2.get(id0,-1) == -1:\n",
    "            continue\n",
    "        if id_label.get(id1,-1) == -1 and id_label2.get(id1,-1) == -1:\n",
    "            continue\n",
    "        if id_label2.get(id0,-1) != -1 or id_label2.get(id1,-1) != -1:\n",
    "            if same_id_dict.get(id0,id0) != same_id_dict.get(id1,id1):\n",
    "                id_pair.append(line)\n",
    "    \n",
    "        if id2cluster.get(id0,-1) == -1 and id2cluster.get(id1,-1) == -1:\n",
    "            cluster2id[clusterid] = set()\n",
    "            cluster2id[clusterid].add(id0)\n",
    "            cluster2id[clusterid].add(id1)\n",
    "            id2cluster[id0] = clusterid\n",
    "            id2cluster[id1] = clusterid\n",
    "            clusterid += 1\n",
    "        elif id2cluster.get(id0,-1) != -1 or id2cluster.get(id1,-1) != -1:\n",
    "            if id2cluster.get(id0,-1) != -1:\n",
    "                clusterid_temp = id2cluster[id0]\n",
    "                cluster2id[clusterid_temp].add(id1)\n",
    "                id2cluster[id1] = clusterid_temp\n",
    "            if id2cluster.get(id1,-1) != -1:\n",
    "                clusterid_temp = id2cluster[id1]\n",
    "                cluster2id[clusterid_temp].add(id0)\n",
    "                id2cluster[id0] = clusterid_temp\n",
    "\n",
    "    clusterinfo = {}\n",
    "    valid_y = []\n",
    "    pred_y = []\n",
    "    for k,v in cluster2id.items():\n",
    "        l = list(v)\n",
    "        info = [0,0,0]\n",
    "        for id in l:\n",
    "            if id_label.get(id,-1) == -1:\n",
    "                info[2] +=1\n",
    "            if id_label.get(id,-1) != -1:\n",
    "                info[id_label.get(id,-1)] += 1\n",
    "\n",
    "                \n",
    "        distinct_id = set()\n",
    "        for id in l:\n",
    "            temp_id = id\n",
    "            while(True):\n",
    "                if same_id_dict.get(temp_id, -1) != -1:\n",
    "                    temp_id = same_id_dict[temp_id]\n",
    "                else:\n",
    "                    break\n",
    "            distinct_id.add(temp_id)\n",
    "        \n",
    "        for id in l:\n",
    "            id_sample_weight[id] = 1/len(l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/04/2020 11:18:42 - INFO - transformers.configuration_utils -   loading configuration file ../input/roberta-base/config.json\n",
      "11/04/2020 11:18:42 - INFO - transformers.configuration_utils -   Model config {\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": true,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "11/04/2020 11:18:42 - INFO - transformers.modeling_utils -   loading weights file ../input/roberta-base/pytorch_model.bin\n",
      "11/04/2020 11:19:19 - INFO - transformers.configuration_utils -   loading configuration file ../input/roberta-base/config.json\n",
      "11/04/2020 11:19:19 - INFO - transformers.configuration_utils -   Model config {\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": true,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "11/04/2020 11:19:19 - INFO - transformers.modeling_utils -   loading weights file ../input/roberta-base/pytorch_model.bin\n",
      "11/04/2020 11:19:52 - INFO - transformers.configuration_utils -   loading configuration file ../input/roberta-base/config.json\n",
      "11/04/2020 11:19:52 - INFO - transformers.configuration_utils -   Model config {\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": true,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "11/04/2020 11:19:52 - INFO - transformers.modeling_utils -   loading weights file ../input/roberta-base/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "criterion2 = nn.BCEWithLogitsLoss(reduction = 'none')\n",
    "\n",
    "\n",
    "batch_size = 16\n",
    "pair_batch_size = 8\n",
    "valid_batch_num = 16\n",
    "ep_num = 100\n",
    "n_batches = len(ids_list)//batch_size + 1\n",
    "valid_batch_num = len(ids_list3)//batch_size + 1\n",
    "\n",
    "\n",
    "id_pred_mid_all = []\n",
    "id_pred_all = []\n",
    "for fold in range(3):\n",
    "    model = DensNet()\n",
    "    model.to('cuda')\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5, betas=(0.9, 0.999))\n",
    "    if ISPREDICT:\n",
    "        model.load_state_dict(torch.load(weight_path + '/model12_1_' + str(fold) + '.pt'))\n",
    "    else:\n",
    "        for ep in range(5):\n",
    "            print('ep',ep)\n",
    "            random.shuffle(ids_list)\n",
    "            random.shuffle(img_pairs)\n",
    "            random.shuffle(text_pairs)\n",
    "            model.train()\n",
    "            tloss = 0.0\n",
    "            for b in range(n_batches):\n",
    "                start = b*batch_size\n",
    "                end = (b+1)*batch_size\n",
    "                batch_ids = ids_list[start:end]\n",
    "                batch_images = []\n",
    "                batch_feat = []\n",
    "                batch_text = []\n",
    "                batch_text2 = []\n",
    "                sample_weight = []\n",
    "                y = []\n",
    "                for i,id in enumerate(batch_ids):\n",
    "                    if len(batch_ids) == 0:\n",
    "                        continue\n",
    "                    try:\n",
    "                        batch_images.append(pic_cache[id])\n",
    "                        batch_feat.append(id_feat[id])\n",
    "                        y.append([id_label[id],id_label[id],id_label[id]])\n",
    "                        sample_weight.append([(max(id_sample_weight.get(id,1),0.2)) * 0.7 + id_weight_nltk.get(id,1) * 0.3])\n",
    "                        text_feat = get_input_data(id_text[id])\n",
    "                        batch_text.append(text_feat[0])\n",
    "                        batch_text2.append(text_feat[1])\n",
    "                    except:\n",
    "                        print(id,str(traceback.format_exc()))\n",
    "\n",
    "        #         print(';2',b)\n",
    "                y = torch.FloatTensor(y).to('cuda')\n",
    "                batch_feat = torch.FloatTensor(batch_feat).to('cuda')\n",
    "                batch_images = torch.FloatTensor(batch_images).to('cuda')\n",
    "                batch_text = torch.stack(batch_text, 0).to('cuda')\n",
    "                batch_text2 = torch.stack(batch_text2, 0).to('cuda')\n",
    "                sample_weight = torch.FloatTensor(sample_weight).to('cuda')\n",
    "                output = model.forward2([batch_images.permute(0,3,1,2),batch_text,batch_text2,batch_feat])\n",
    "                loss = (criterion2((output), y) * sample_weight).mean()\n",
    "                loss.backward()\n",
    "                if b % 2 == 0:\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "                tloss += loss.item() \n",
    "\n",
    "            print(\"loss:\",tloss/len(ids_list))\n",
    "            \n",
    "    if True:\n",
    "        model.eval()\n",
    "        id_pred_mid = {}\n",
    "        id_pred = {}\n",
    "        for b in range(valid_batch_num):\n",
    "            start = b*batch_size\n",
    "            end = (b+1)*batch_size\n",
    "            if start >= len(ids_list3):\n",
    "                continue\n",
    "            batch_ids = ids_list3[start:end]\n",
    "            batch_images = []\n",
    "            batch_feat = []\n",
    "            batch_text = []\n",
    "            batch_text2 = []\n",
    "            y = []\n",
    "            for i,id in enumerate(batch_ids):\n",
    "                if len(batch_ids) == 0:\n",
    "                    continue\n",
    "                try:\n",
    "                    batch_images.append(pic_cache[id])\n",
    "                    y.append(id_label2[id])\n",
    "                    batch_feat.append(id_feat[id])\n",
    "                    text_feat = get_input_data(id_text[id])\n",
    "                    batch_text.append(text_feat[0])\n",
    "                    batch_text2.append(text_feat[1])\n",
    "                except:\n",
    "                    print(id,str(traceback.format_exc()))\n",
    "\n",
    "            batch_images = torch.FloatTensor(batch_images).to('cuda')\n",
    "            batch_feat = torch.FloatTensor(batch_feat).to('cuda')\n",
    "            batch_text = torch.stack(batch_text, 0).to('cuda')\n",
    "            batch_text2 = torch.stack(batch_text2, 0).to('cuda')\n",
    "            output = model.forward2([batch_images.permute(0,3,1,2),batch_text,batch_text2,batch_feat])\n",
    "            temp = F.sigmoid(output).tolist()\n",
    "            for i,id in enumerate(batch_ids):\n",
    "                id_pred_mid[id] = temp[i]\n",
    "            output = output[:,0] - (output[:,1] + output[:,2]) * 0.5\n",
    "            valid_y2 = torch.FloatTensor(y).to('cuda')\n",
    "            output2 = F.sigmoid(output)\n",
    "            temp = F.sigmoid(output).view(-1).tolist()\n",
    "            for i,id in enumerate(batch_ids):\n",
    "                id_pred[id] = temp[i]\n",
    "\n",
    "        if MODE == \"VALID\":\n",
    "            pred_y = []\n",
    "            valid_y = []\n",
    "            for id in ids_list3:\n",
    "                pred_y.append(id_pred[id])\n",
    "                valid_y.append(id_label2[id])\n",
    "            print(sklearn.metrics.roc_auc_score(valid_y,pred_y),\n",
    "                  sklearn.metrics.accuracy_score(valid_y,np.array(pred_y)>0.5),\n",
    "                  sklearn.metrics.log_loss(valid_y,np.array(pred_y)))\n",
    "        \n",
    "        \n",
    "\n",
    "    if not ISPREDICT:\n",
    "        torch.save(model.state_dict(), './weights/model12_1_' + str(fold) + '.pt')\n",
    "    id_pred_mid_all.append(id_pred_mid)   \n",
    "    id_pred_all.append(id_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/04/2020 11:20:27 - INFO - transformers.configuration_utils -   loading configuration file ../input/roberta-base/config.json\n",
      "11/04/2020 11:20:27 - INFO - transformers.configuration_utils -   Model config {\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": true,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "11/04/2020 11:20:27 - INFO - transformers.modeling_utils -   loading weights file ../input/roberta-base/pytorch_model.bin\n",
      "11/04/2020 11:21:57 - INFO - transformers.configuration_utils -   loading configuration file ../input/roberta-base/config.json\n",
      "11/04/2020 11:21:57 - INFO - transformers.configuration_utils -   Model config {\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": true,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "11/04/2020 11:21:57 - INFO - transformers.modeling_utils -   loading weights file ../input/roberta-base/pytorch_model.bin\n",
      "11/04/2020 11:23:27 - INFO - transformers.configuration_utils -   loading configuration file ../input/roberta-base/config.json\n",
      "11/04/2020 11:23:27 - INFO - transformers.configuration_utils -   Model config {\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": true,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "11/04/2020 11:23:27 - INFO - transformers.modeling_utils -   loading weights file ../input/roberta-base/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "criterion2 = nn.BCEWithLogitsLoss(reduction = 'none')\n",
    "\n",
    "batch_size = 16\n",
    "pair_batch_size = 4\n",
    "valid_batch_num = 16\n",
    "n_batches = len(ids_list)//batch_size + 1\n",
    "valid_batch_num = len(ids_list3)//batch_size + 1\n",
    "valid_pair_batch_num = len(id_pair)//pair_batch_size + 1\n",
    "\n",
    "\n",
    "id_pred2_all = []\n",
    "for fold in range(3):\n",
    "    model = DensNet()\n",
    "    model.to('cuda')\n",
    "    optimizer2 = torch.optim.AdamW(model.parameters(), lr=1.5e-5, betas=(0.9, 0.999))\n",
    "    if ISPREDICT:\n",
    "        model.load_state_dict(torch.load(weight_path + '/model12_2_' + str(fold) + '.pt'))\n",
    "    else:\n",
    "        for ep in range(6):\n",
    "            print('ep',ep)\n",
    "            random.shuffle(img_pairs)\n",
    "            random.shuffle(text_pairs)\n",
    "            model.train()\n",
    "            tloss2 = 0.0\n",
    "            tloss3 = 0.0\n",
    "            for b in range(n_batches):\n",
    "                pairs_backward = False\n",
    "                for pairs in [img_pairs,text_pairs]:\n",
    "                    start = b*pair_batch_size\n",
    "                    end = (b+1)*pair_batch_size\n",
    "                    if start >= len(pairs):\n",
    "                        continue\n",
    "                    batch_ids = pairs[start:end]\n",
    "                    batch_images_x1 = []\n",
    "                    batch_images_x2 = []\n",
    "                    batch_text_x = []\n",
    "                    batch_text2_x = []\n",
    "                    batch_text_x2 = []\n",
    "                    batch_text2_x2 = []\n",
    "                    batch_feat_x1 = []\n",
    "                    batch_feat_x2 = []\n",
    "                    y = []\n",
    "                    for i,id in enumerate(batch_ids):\n",
    "                        if len(batch_ids) == 0:\n",
    "                            continue\n",
    "                        try:\n",
    "                            if random.random() > 0.5:\n",
    "                                id1 = id[0]\n",
    "                                id2 = id[1]\n",
    "                            else:\n",
    "                                id1 = id[1]\n",
    "                                id2 = id[0]\n",
    "                            batch_images_x1.append(pic_cache[id1])\n",
    "                            batch_images_x2.append(pic_cache[id2])\n",
    "                            batch_feat_x1.append(id_feat[id1])\n",
    "                            batch_feat_x2.append(id_feat[id2])\n",
    "                            text_feat = get_input_data(id_text[id1])\n",
    "                            batch_text_x.append(text_feat[0])\n",
    "                            batch_text2_x.append(text_feat[1])\n",
    "                            text_feat = get_input_data(id_text[id2])\n",
    "                            batch_text_x2.append(text_feat[0])\n",
    "                            batch_text2_x2.append(text_feat[1])                    \n",
    "                            y.append([id_label.get(id1,-1),id_label.get(id2,-1)])\n",
    "\n",
    "                        except:\n",
    "                            print(id,str(traceback.format_exc()))\n",
    "                    y = torch.FloatTensor(y).to('cuda')\n",
    "                    batch_images_x1 = torch.FloatTensor(batch_images_x1).to('cuda')\n",
    "                    batch_images_x2 = torch.FloatTensor(batch_images_x2).to('cuda')\n",
    "                    batch_feat_x1 = torch.FloatTensor(batch_feat_x1).to('cuda')\n",
    "                    batch_feat_x2 = torch.FloatTensor(batch_feat_x2).to('cuda')\n",
    "                    batch_text_x = torch.stack(batch_text_x, 0).to('cuda')\n",
    "                    batch_text2_x = torch.stack(batch_text2_x, 0).to('cuda')\n",
    "                    batch_text_x2 = torch.stack(batch_text_x2, 0).to('cuda')\n",
    "                    batch_text2_x2 = torch.stack(batch_text2_x2, 0).to('cuda')\n",
    "                    output = model.pair_forward(x1 = [batch_images_x1.permute(0,3,1,2),batch_text_x,batch_text2_x,batch_feat_x1],\n",
    "                                        x2 = [batch_images_x2.permute(0,3,1,2),batch_text_x2,batch_text2_x2,batch_feat_x2])\n",
    "                    output2 = F.sigmoid(output)\n",
    "                    loss = criterion2(output.view(-1), y.view(-1))\n",
    "                    loss = loss * (1 - (y.view(-1) == -1).float()) * 0.3\n",
    "                    loss2 = F.relu(0.3 - (output2[:,0] - output2[:,1]) * \n",
    "                                   (y[:,0] - y[:,1])) * abs(y[:,0] - y[:,1]) * (1 - (y[:,0] == -1).float()) * (1 - (y[:,1] == -1).float())\n",
    "                    loss3 = loss.mean() + loss2.mean()\n",
    "                    loss3.backward()\n",
    "                    pairs_backward = True\n",
    "                    tloss2 += loss.mean().item()\n",
    "                    tloss3 += loss2.mean().item()\n",
    "                if b % 3 == 0 and pairs_backward:\n",
    "                    optimizer2.step()\n",
    "                    optimizer2.zero_grad()\n",
    "\n",
    "            print(\"loss:\",tloss2/len(ids_list),tloss3/len(ids_list))\n",
    "    if True:\n",
    "        model.eval()\n",
    "\n",
    "        id_pred2 = {}\n",
    "        for b in range(valid_pair_batch_num):\n",
    "            start = b*pair_batch_size\n",
    "            end = (b+1)*pair_batch_size\n",
    "            if start >= len(id_pair):\n",
    "                continue\n",
    "            batch_ids = id_pair[start:end]\n",
    "            batch_images_x1 = []\n",
    "            batch_images_x2 = []\n",
    "            batch_text_x = []\n",
    "            batch_text2_x = []\n",
    "            batch_text_x2 = []\n",
    "            batch_text2_x2 = []\n",
    "            batch_feat_x1 = []\n",
    "            batch_feat_x2 = []\n",
    "            y = []\n",
    "            for i,id in enumerate(batch_ids):\n",
    "                if len(batch_ids) == 0:\n",
    "                    continue\n",
    "                try:\n",
    "                    id1 = id[0]\n",
    "                    id2 = id[1]\n",
    "                    batch_images_x1.append(pic_cache[id1])\n",
    "                    batch_images_x2.append(pic_cache[id2])\n",
    "                    batch_feat_x1.append(id_feat[id1])\n",
    "                    batch_feat_x2.append(id_feat[id2])\n",
    "                    text_feat = get_input_data(id_text[id1])\n",
    "                    batch_text_x.append(text_feat[0])\n",
    "                    batch_text2_x.append(text_feat[1])\n",
    "                    text_feat = get_input_data(id_text[id2])\n",
    "                    batch_text_x2.append(text_feat[0])\n",
    "                    batch_text2_x2.append(text_feat[1])                    \n",
    "                    y.append([id_label2.get(id1,-1),id_label2.get(id2,-1)])\n",
    "\n",
    "                except:\n",
    "                    print(id,str(traceback.format_exc()))\n",
    "            y = torch.FloatTensor(y).to('cuda')\n",
    "            batch_images_x1 = torch.FloatTensor(batch_images_x1).to('cuda')\n",
    "            batch_images_x2 = torch.FloatTensor(batch_images_x2).to('cuda')\n",
    "            batch_feat_x1 = torch.FloatTensor(batch_feat_x1).to('cuda')\n",
    "            batch_feat_x2 = torch.FloatTensor(batch_feat_x2).to('cuda')\n",
    "            batch_text_x = torch.stack(batch_text_x, 0).to('cuda')\n",
    "            batch_text2_x = torch.stack(batch_text2_x, 0).to('cuda')\n",
    "            batch_text_x2 = torch.stack(batch_text_x2, 0).to('cuda')\n",
    "            batch_text2_x2 = torch.stack(batch_text2_x2, 0).to('cuda')\n",
    "            output = model.pair_forward(x1 = [batch_images_x1.permute(0,3,1,2),batch_text_x,batch_text2_x,batch_feat_x1],\n",
    "                                    x2 = [batch_images_x2.permute(0,3,1,2),batch_text_x2,batch_text2_x2,batch_feat_x2])\n",
    "            output2 = F.sigmoid(output)\n",
    "            temp = F.sigmoid(output).tolist()\n",
    "            for i,id in enumerate(batch_ids):\n",
    "                id1 = id[0]\n",
    "                id2 = id[1]\n",
    "                id_pred2[id1] = id_pred2.get(id1,[])\n",
    "                id_pred2[id2] = id_pred2.get(id2,[])\n",
    "                id_pred2[id1].append(temp[i][0])\n",
    "                id_pred2[id2].append(temp[i][1])\n",
    "                \n",
    "        if MODE == \"VALID\":\n",
    "            valid_y2 = []    \n",
    "            pred_y2 = []\n",
    "            for id,prob in id_pred2.items():\n",
    "                if id_label2.get(id,-1) == -1:\n",
    "                    continue\n",
    "                pred_y2.append(sum(id_pred2[id])/len(id_pred2[id]))\n",
    "                valid_y2.append(id_label2[id])\n",
    "            print(sklearn.metrics.roc_auc_score(valid_y2,pred_y2), \n",
    "                  sklearn.metrics.accuracy_score(valid_y2,np.array(pred_y2)>0.5),\n",
    "                  sklearn.metrics.log_loss(valid_y2,np.array(pred_y2)))\n",
    "        \n",
    "    if not ISPREDICT:\n",
    "        torch.save(model.state_dict(), weight_path + '/model12_2_' + str(fold) + '.pt')\n",
    "    id_pred2_all.append(id_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_pred_2 = {}\n",
    "for id in ids_list3:\n",
    "    id_pred_2[id] = (id_pred_all[0][id] +  id_pred_all[1][id] + id_pred_all[2][id])/3\n",
    "            \n",
    "id_pred2_2 = {}\n",
    "for id,prob in id_pred2_all[0].items():\n",
    "    if id_label2.get(id,-1) == -1:\n",
    "        continue\n",
    "    id_pred2_2[id] = np.mean([np.mean(id_pred2_all[0][id]),np.mean(id_pred2_all[1][id]),np.mean(id_pred2_all[2][id])])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.66443142 0.69172965 0.31716553]\n",
      " [0.66443142 1.         0.67788095 0.30923247]\n",
      " [0.69172965 0.67788095 1.         0.32198209]\n",
      " [0.31716553 0.30923247 0.32198209 1.        ]]\n",
      "[[1.         0.61196715 0.65335025 0.31524996]\n",
      " [0.61196715 1.         0.6079636  0.26130578]\n",
      " [0.65335025 0.6079636  1.         0.31155336]\n",
      " [0.31524996 0.26130578 0.31155336 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# check corrcoef\n",
    "id_pred2_1_np = [[],[],[],[]]\n",
    "for id,prob in id_pred_all[0].items():\n",
    "    id_pred2_1_np[0].append(id_pred_all[0][id])\n",
    "    id_pred2_1_np[1].append(id_pred_all[1][id])\n",
    "    id_pred2_1_np[2].append(id_pred_all[2][id])\n",
    "    id_pred2_1_np[3].append(id_mmf.get(id,0))\n",
    "print(np.corrcoef(np.stack(id_pred2_1_np)))\n",
    "\n",
    "id_pred2_2_np = [[],[],[],[]]\n",
    "for id,prob in id_pred2_all[0].items():\n",
    "    if id_label2.get(id,-1) == -1:\n",
    "        continue\n",
    "    id_pred2_2_np[0].append(np.mean(id_pred2_all[0][id]))\n",
    "    id_pred2_2_np[1].append(np.mean(id_pred2_all[1][id]))\n",
    "    id_pred2_2_np[2].append(np.mean(id_pred2_all[2][id]))\n",
    "    id_pred2_2_np[3].append(id_mmf.get(id,0))\n",
    "print(np.corrcoef(np.stack(id_pred2_2_np)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "f = open(\"./submission12.pkl\", 'wb')\n",
    "pickle.dump([id_pred_2,id_pred2_2,id_mmf], f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9013093508874948 0.8328125 0.12810842705009146\n"
     ]
    }
   ],
   "source": [
    "f = open('./submission12.csv','w')\n",
    "print(\"id,proba,label\",file = f )\n",
    "id_pred3 = {}\n",
    "count = 0\n",
    "for id in ids_list3:\n",
    "    if id_pred2.get(id,-1) != -1:\n",
    "        id_pred3[id] =  (id_pred_2[id] * 0.3 + np.mean(id_pred2_2[id]) * 0.3 + id_mmf[id] * 0.4)\n",
    "    else:\n",
    "        id_pred3[id] =  id_pred_2[id]*0.5 + id_mmf[id] * 0.5\n",
    "        \n",
    "    if id_rule.get(id,-1) != -1:\n",
    "        id_pred3[id] =  id_rule[id] * 0.8 + id_pred3[id] * 0.2\n",
    "    elif id_rule_test1.get(same_id_dict.get(id,id),-1) != -1:\n",
    "        id_pred3[id] =  id_rule_test1[same_id_dict.get(id,id)] * 0.8 + id_pred3[id] * 0.2   \n",
    "        \n",
    "usedset = {}\n",
    "for id in id_pair:\n",
    "    a0 = 0.7\n",
    "    a1 = 0.7\n",
    "    if id_label2.get(id[0],-1) != -1 and id_label2.get(id[1],-1) != -1:\n",
    "\n",
    "        b = abs(np.mean(id_pred2_2[id[0]]) - np.mean(id_pred2_2[id[1]])) / 0.4\n",
    "        b = max(1.0,min(2.0,b))\n",
    "        a0 = a0/b\n",
    "        a1 = a1/b\n",
    "#         print(b,a0,a1)\n",
    "        if np.mean(id_pred2_2[id[0]]) > np.mean(id_pred2_2[id[1]]):\n",
    "            id_pred3[id[0]] = id_pred3[id[0]] * a0 + 1.0 * (1 - a0)\n",
    "            id_pred3[id[1]] = id_pred3[id[1]] * a1 + 0.0 * (1 - a1)\n",
    "        else:\n",
    "            id_pred3[id[0]] = id_pred3[id[0]] * a0 + 0.0 * (1 - a0)\n",
    "            id_pred3[id[1]] = id_pred3[id[1]] * a1 + 1.0 * (1 - a1)\n",
    "        usedset[id[0]] = usedset.get(id[0], 0) + 1\n",
    "        usedset[id[1]] = usedset.get(id[1], 0) + 1\n",
    "    elif id_label.get(id[0],-1) != -1 and id_rule.get(id[1],-1) == -1:\n",
    "        a0 = 0.85\n",
    "        a1 = 0.85\n",
    "        if id_label[id[0]] > np.mean(id_pred2_2[id[1]]):\n",
    "            id_pred3[id[1]] = id_pred3[id[1]] * a1 + 0.0 * (1 - a1)\n",
    "        else:\n",
    "            id_pred3[id[1]] = id_pred3[id[1]] * a1 + 1.0 * (1 - a1)\n",
    "    elif id_label.get(id[1],-1) != -1 and id_rule.get(id[0],-1) == -1:\n",
    "        a0 = 0.85\n",
    "        a1 = 0.85\n",
    "        if id_label[id[1]] > np.mean(id_pred2_2[id[0]]):\n",
    "            id_pred3[id[0]] = id_pred3[id[0]] * a1 + 0.0 * (1 - a1)\n",
    "        else:\n",
    "            id_pred3[id[0]] = id_pred3[id[0]] * a1 + 1.0 * (1 - a1)\n",
    "\n",
    "usedset = {}\n",
    "for id in id_pair:\n",
    "    a0 = 0.4\n",
    "    a1 = 0.4\n",
    "    if id_label2.get(id[0],-1) != -1 and id_label2.get(id[1],-1) != -1:\n",
    "\n",
    "        if id_mmf[id[0]] > id_mmf[id[1]]:\n",
    "            if 1 - id_pred3[id[0]] > id_pred3[id[1]]:\n",
    "                id_pred3[id[0]] = np.clip(id_pred3[id[0]] + a0,0,1)\n",
    "            else:\n",
    "                id_pred3[id[1]] = np.clip(id_pred3[id[1]] - a1,0,1)\n",
    "\n",
    "        else:\n",
    "            if 1 - id_pred3[id[1]] > id_pred3[id[0]]:\n",
    "                id_pred3[id[1]] = np.clip(id_pred3[id[1]] + a0,0,1)\n",
    "            else:\n",
    "                id_pred3[id[0]] = np.clip(id_pred3[id[0]] - a1,0,1)\n",
    "        usedset[id[0]] = usedset.get(id[0], 0) + 1\n",
    "        usedset[id[1]] = usedset.get(id[1], 0) + 1\n",
    "        \n",
    "for id in id_pair:\n",
    "    a = 0.6\n",
    "    if id_label2.get(id[0],-1) != -1 and id_label2.get(id[1],-1) != -1:\n",
    "        meanscore = (id_pred3[id[0]] + id_pred3[id[1]]) * 0.5\n",
    "        \n",
    "        id_pred3[id[0]] = id_pred3[id[0]] - (meanscore - 0.5) * a\n",
    "        id_pred3[id[1]] = id_pred3[id[1]] - (meanscore - 0.5) * a\n",
    "            \n",
    "pred_y = []\n",
    "valid_y = []\n",
    "if MODE == 'TEST':\n",
    "    for id in test2.id.values:\n",
    "        print(\",\".join([str(id),str(round(id_pred3[id],4)),str(1 if id_pred3[id] > 0.5 else 0)]),file = f )\n",
    "else:\n",
    "    for id in train2.id.values:\n",
    "        pred_y.append(id_pred3[id])\n",
    "        valid_y.append(id_label2[id])\n",
    "        print(\",\".join([str(id),str(round(id_pred3[id],4)),str(1 if id_pred3[id] > 0.5 else 0)]),file = f )\n",
    "    print(sklearn.metrics.roc_auc_score(valid_y,pred_y), \n",
    "          sklearn.metrics.accuracy_score(valid_y,np.array(pred_y)>0.5),tloss/len(valid_y2))\n",
    "f.close()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
